{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c4becd-34dd-4df1-a0a4-74cbdb3d902b",
   "metadata": {},
   "source": [
    "## Goal: Generate IGVF perturb-seq metadata information given input .fasta file with protospacer sequences\n",
    "\n",
    "Requirements: https://docs.google.com/document/d/1Z1SOlekIE5uGyXW41XxnszxaYdSw0wdAOUVzfy3fj3M/edit?tab=t.0#heading=h.lw69v09vjkrr\n",
    "\n",
    "Example file: /hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/example_perturbseq_seqfile.tsv\n",
    "\n",
    "Note: I was having trouble with BLAT CLI so I used webtool to get most fields. Still need PAM and TSS coordinate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25cc15-87a9-4b60-8a32-d4c091dc30e1",
   "metadata": {},
   "source": [
    "### Extract PAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b57035f-68fa-4b33-b5ab-043d6b1807ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedtools 2.30.0\u001b[m\n",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "index file /hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/perturb-seq_metadata/hg38.fa.fai not found, generating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [guide_id, PAM_sequence]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected file format.  Please use tab-delimited BED, GFF, or VCF. Perhaps you have non-integer starts or ends at line 1?\n"
     ]
    }
   ],
   "source": [
    "!module load Bedtools/2.30.0 \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def compute_upstream_with_pam(df, genome_fasta=\"/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/perturb-seq_metadata/hg38.fa\"):\n",
    "    output_bed = \"temp_upstream.bed\"\n",
    "    output_fasta = \"temp_upstream.fa\"\n",
    "\n",
    "    upstream_data = []\n",
    "\n",
    "    with open(output_bed, \"w\") as bed:\n",
    "        for _, row in df.iterrows():\n",
    "            chrom = row[\"guide_chr\"]\n",
    "            start = row[\"guide_start\"]\n",
    "            end = row[\"guide_end\"]\n",
    "            strand = row[\"strand\"]\n",
    "            guide_id = row[\"guide_id\"]\n",
    "\n",
    "            # Cas9 PAM (NGG) is on the 3' end of the guide\n",
    "            if strand == \"+\":\n",
    "                pam_start = end  # NGG is immediately downstream\n",
    "                pam_end = end + 3  # Three bases downstream\n",
    "            else:\n",
    "                pam_start = start - 3  # Three bases upstream for reverse strand\n",
    "                pam_end = start  \n",
    "\n",
    "            # Write to BED file\n",
    "            bed.write(f\"{chrom}\\t{pam_start}\\t{pam_end}\\t{guide_id}\\t.\\t{strand}\\n\")\n",
    "\n",
    "    # Run bedtools getfasta to extract sequence\n",
    "    bedtools_path = \"/opt/apps/rhel8/bedtools-2.30.0/bin/bedtools\"\n",
    "    os.system(f\"{bedtools_path} getfasta -fi {genome_fasta} -bed {output_bed} -fo {output_fasta} -s\")\n",
    "\n",
    "    # Read extracted sequences\n",
    "    with open(output_fasta, \"r\") as fasta:\n",
    "        sequences = fasta.read().splitlines()\n",
    "\n",
    "    # Process FASTA output\n",
    "    for i in range(0, len(sequences), 2):  # FASTA format is >header, seq\n",
    "        guide_id = sequences[i].strip(\">\").split(\":\")[0]  # Extract guide_id from header\n",
    "        pam_seq = sequences[i + 1]  # Extract PAM sequence\n",
    "\n",
    "        upstream_data.append([guide_id, pam_seq])\n",
    "\n",
    "    # Create DataFrame\n",
    "    upstream_df = pd.DataFrame(upstream_data, columns=[\"guide_id\", \"PAM_sequence\"])\n",
    "    \n",
    "    # Save output\n",
    "    upstream_df.to_csv(\"upstream_regions_with_pam.csv\", sep=\",\", index=False)\n",
    "    return upstream_df\n",
    "\n",
    "# Read input CSV\n",
    "df = pd.read_csv(\"/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/perturb-seq_metadata/PAM_input.csv\", sep=\",\")  # Adjust separator if needed\n",
    "\n",
    "# Compute upstream regions and extract PAM\n",
    "upstream_df = compute_upstream_with_pam(df)\n",
    "\n",
    "print(upstream_df.head())  # Show output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fc1b9b9-a1ca-4d55-94df-6524ef743588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "831e5bba-0088-4694-9fee-025c3bb5ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected fieldnames: ['\\ufeffgene', 'protospacer', 'oligo']\n",
      "{'\\ufeffgene': 'ADNP.1', 'protospacer': 'AACCCCCCCTGGGGAAAAGG', 'oligo': 'ATATATCTTGTGGAAAGGACGAAACACCGAACCCCCCCTGGGGAAAAGGGTTTAAGAGCTATGCTGGAAACAGCATAG'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/grna_libs/SJR_CRISPRa_TF_lib_final.csv', 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    print(\"Detected fieldnames:\", reader.fieldnames)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        break  # Just check the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53b5455-861c-4b20-ac89-e214dd253045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "input_csv = '/work/rr151/SamAIM2neuro_data/subtype_lib.csv'\n",
    "output_fasta = '/work/rr151/SamAIM2neuro_data/SJR_subtype_lib_final.fasta'\n",
    "with open(input_csv, 'r', newline='') as csvfile, open(output_fasta, 'w') as fastafile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader.fieldnames = [field.strip().replace('\\ufeff', '') for field in reader.fieldnames]\n",
    "    for row in reader:\n",
    "        gene = row['gene'].strip()\n",
    "        spacer = row['protospacer'].strip()\n",
    "        fastafile.write(f'>{gene}\\n{spacer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee85cd1c-1ad1-4e27-903e-47eba0d24859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bowtie2 2.4.4-rhel8\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "module load Bowtie2/2.4.4-rhel8\n",
    "#module load Bowtie/1.2.2\n",
    "#bowtie2-build '/hpc/group/gersbachlab/Reference_Data/Genomes/hg38/hg38.fa' '/work/rr151/SamAIM2neuro_data/hg38_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049db69e-1d98-40b5-b5f7-321a05e8c556",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-c898449e6a35>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-c898449e6a35>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    echo \"Parsing SAM to metadata...\"\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "# Inputs\n",
    "FASTA=\"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final.fasta\"\n",
    "BOWTIE_INDEX=\"/work/rr151/SamAIM2neuro_data/hg38_index\"\n",
    "SAM_OUT=\"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final.sam\"\n",
    "TSV_OUT=\"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final_metadata.tsv\"\n",
    "\n",
    "#module load Bowtie2/2.4.4-rhel8\n",
    "# Step 1: Align using Bowtie\n",
    "#echo \"Running Bowtie...\"\n",
    "#bowtie -f -v 0 -a --best --strata $BOWTIE_INDEX $FASTA > $SAM_OUT\n",
    "#bowtie2 -f -x $BOWTIE_INDEX -U $FASTA -S $SAM_OUT\n",
    "#bowtie2 -f -x /work/rr151/SamAIM2neuro_data/hg38_index -U SJR_subtype_lib_final.fasta -S SJR_subtype_lib_final.sam\n",
    "# Step 2: Generate metadata\n",
    "echo \"Parsing SAM to metadata...\"\n",
    "#python3 /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_metadata.py $FASTA $SAM_OUT $TSV_OUT\n",
    "python3 /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_metadata.py $SAM_OUT $TSV_OUT\n",
    "echo \"Done. Metadata written to $TSV_OUT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4c743a-a6fd-469c-a21c-0264fa0fbd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_metadata.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_metadata.py\n",
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "#from Bio import SeqIO\n",
    "# Inputs from command line\n",
    "#fasta_file = sys.argv[1]\n",
    "sam_file = sys.argv[1]\n",
    "output_file = sys.argv[2]\n",
    "\n",
    "import csv\n",
    "input_csv = '/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/grna_libs/SJR_CRISPRa_TF_lib_final.csv'\n",
    "output_fasta = '/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final2.fasta'\n",
    "guides = {}\n",
    "with open(input_csv, 'r', newline='') as csvfile, open(output_fasta, 'w') as fastafile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader.fieldnames = [field.strip().replace('\\ufeff', '') for field in reader.fieldnames]\n",
    "    for row in reader:\n",
    "        gene = row['gene'].strip()\n",
    "        spacer = row['protospacer'].strip()\n",
    "        guides[gene] = spacer\n",
    "        fastafile.write(f'>{gene}\\n{spacer}\\n')\n",
    "# Parse FASTA\n",
    "#guides = {}\n",
    "#for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "#    guides[record.id] = str(record.seq)\n",
    "\n",
    "# Parse SAM\n",
    "metadata = {}\n",
    "with open(sam_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"@\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        guide_id = parts[0]\n",
    "        guide_chr = parts[2]\n",
    "        guide_start = int(parts[3])  # 1-based\n",
    "        flag = int(parts[1])\n",
    "        strand = \"-\" if flag & 16 else \"+\"\n",
    "        seq = parts[9]\n",
    "        pam = seq[-3:] if len(seq) >= 3 else \"\"\n",
    "        guide_end = guide_start + len(seq) - 1\n",
    "        # Overwrite only if not already present (first alignment)\n",
    "        if guide_id not in metadata:\n",
    "            metadata[guide_id] = {\n",
    "                \"guide_id\": guide_id,\n",
    "                \"spacer\": guides.get(guide_id, \"\"),\n",
    "                \"targeting\": \"TRUE\",\n",
    "                \"type\": \"targeting\",\n",
    "                \"guide_chr\": guide_chr,\n",
    "                \"guide_start\": guide_start,\n",
    "                \"guide_end\": guide_end,\n",
    "                \"strand\": strand,\n",
    "                \"pam\": pam,\n",
    "                \"genomic_element\": \"promoter\",\n",
    "                \"intended_target_name\": guide_id,  # Will be updated with Ensembl ID\n",
    "                \"intended_target_chr\": guide_chr,\n",
    "                \"intended_target_start\": \"\",\n",
    "                \"intended_target_end\": \"\",\n",
    "                \"putative_target_genes\": intended_target_name,\n",
    "                \"reporter\": \"\",\n",
    "                \"imperfect\": \"\"               \n",
    "            }\n",
    "# Function to get Ensembl ID from gene symbol\n",
    "def get_ensembl_id(symbol):\n",
    "    url = f\"https://rest.ensembl.org/lookup/symbol/homo_sapiens/{symbol}?content-type=application/json\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        return data.get('id', '')\n",
    "    else:\n",
    "        print(f\"Warning: Could not retrieve Ensembl ID for symbol '{symbol}'. HTTP Status: {response.status_code}\")\n",
    "        return ''\n",
    "# Update intended_target_name with Ensembl IDs\n",
    "for guide_id, info in metadata.items():\n",
    "    gene_symbol = info['intended_target_name']\n",
    "    if gene_symbol:\n",
    "        ensembl_id = get_ensembl_id(gene_symbol)\n",
    "        metadata[guide_id]['intended_target_name'] = ensembl_id\n",
    "# Write TSV\n",
    "headers = [\n",
    "    \"guide_id\", \"spacer\", \"targeting\", \"type\", \"guide_chr\",\n",
    "    \"guide_start\", \"guide_end\", \"strand\", \"pam\", \"genomic_element\",\n",
    "    \"intended_target_name\", \"intended_target_chr\",\n",
    "    \"intended_target_start\", \"intended_target_end\", \"putative_target_genes\", \"reporter\", \"imperfect\"\n",
    "]\n",
    "with open(output_file, \"w\", newline=\"\") as out_f:\n",
    "    writer = csv.DictWriter(out_f, fieldnames=headers, delimiter=\"\\t\")\n",
    "    writer.writeheader()\n",
    "    for guide_id in guides:\n",
    "        row = metadata.get(guide_id, {\n",
    "            \"guide_id\": guide_id,\n",
    "            \"spacer\": guides[guide_id],\n",
    "            \"targeting\": \"TRUE\",\n",
    "            \"type\": \"targeting\",\n",
    "            \"guide_chr\": \"\",\n",
    "            \"guide_start\": \"\",\n",
    "            \"guide_end\": \"\",\n",
    "            \"strand\": \"\",\n",
    "            \"pam\": \"\",\n",
    "            \"genomic_element\": \"\",\n",
    "            \"intended_target_name\": \"\",  # Will be updated with Ensembl ID\n",
    "            \"intended_target_chr\": \"\",\n",
    "            \"intended_target_start\": \"\",\n",
    "            \"intended_target_end\": \"\",\n",
    "            \"putative_target_genes\": \"\",\n",
    "            \"reporter\": \"\",\n",
    "            \"imperfect\": \"\"\n",
    "        })\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10809f53-77ee-45c2-9007-942a906357f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_2_metadata.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_2_metadata.py\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "sam_file = sys.argv[1]\n",
    "output_file = sys.argv[2]\n",
    "\n",
    "# Input files\n",
    "input_csv = \"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final.csv\"         # Your input CSV\n",
    "sam_file = \"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final.sam\"         # Output from Bowtie\n",
    "tss_file = \"/work/rr151/SamAIM2neuro_data/gencode_v47_tss.bed\"            # TSS BED file\n",
    "output_file = \"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final2_metadata.tsv\"    # Final annotated output\n",
    "output_fasta = '/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final2.fasta'\n",
    "# Step 1: Read protospacers from CSV\n",
    "guides = {}  # key = guide ID (gene name), value = spacer sequence\n",
    "guide_symbols = set()\n",
    "with open(input_csv, 'r', newline='') as csvfile, open(output_fasta, 'w') as fastafile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader.fieldnames = [field.strip().replace('\\ufeff', '') for field in reader.fieldnames]\n",
    "    for row in reader:\n",
    "        gene = row[\"gene\"].strip()\n",
    "        spacer = row[\"protospacer\"].strip()\n",
    "        guides[gene] = spacer\n",
    "        guide_symbols.add(gene.upper())\n",
    "#       guides[gene] = spacer\n",
    "        fastafile.write(f'>{gene}\\n{spacer}\\n')\n",
    "# Step 2: Load TSS info\n",
    "#tss_lookup = {}  #  key = gene symbol, value = (chr, start, end, Ensembl ID)\n",
    "#with open(tss_file, \"r\") as f:\n",
    "#    for line in f:\n",
    "#        parts = line.strip().split(\"\\t\")\n",
    "#       if len(parts) < 6:\n",
    "#            continue\n",
    "#        chrom, start, end, ensembl_id, gene_symbol, strand = parts\n",
    "#        tss_lookup[gene_symbol.upper()] = (chrom, int(start), int(end), ensembl_id)\n",
    "\n",
    "# Step 2: Map gene symbols to Ensembl IDs using Ensembl REST API\n",
    "symbol_to_ensembl = {}\n",
    "for symbol in guide_symbols:\n",
    "    url = f\"https://rest.ensembl.org/lookup/symbol/homo_sapiens/{symbol}?content-type=application/json\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            ensembl_id = data.get(\"id\", \"\")\n",
    "            if ensembl_id:\n",
    "                symbol_to_ensembl[symbol] = ensembl_id\n",
    "        else:\n",
    "            print(f\"[Warning] Could not find Ensembl ID for {symbol} (HTTP {response.status_code})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] API call failed for {symbol}: {e}\")\n",
    "    time.sleep(0.1)  # Avoid rate limit\n",
    "# Step 3: Load TSS BED into dict keyed by Ensembl ID\n",
    "tss_lookup = {}  # ensembl_id → (chr, start, end)\n",
    "with open(tss_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        chrom, start, end, ensembl_id = parts[:4]\n",
    "        tss_lookup[ensembl_id] = (chrom, int(start), int(end))\n",
    "\n",
    "# Step 4: Parse SAM file\n",
    "metadata = {}\n",
    "with open(sam_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"@\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        guide_id = parts[0]\n",
    "        guide_chr = parts[2]\n",
    "        guide_start = int(parts[3])\n",
    "        flag = int(parts[1])\n",
    "        strand = \"-\" if flag & 16 else \"+\"\n",
    "        seq = parts[9]\n",
    "        pam = seq[-3:] if len(seq) >= 3 else \"\"\n",
    "        guide_end = guide_start + len(seq) - 1\n",
    "        gene_symbol = guide_id.rsplit(\".\",1)[0].upper()\n",
    "        ensembl_id = symbol_to_ensembl.get(gene_symbol, \"\")\n",
    "        tss = tss_lookup.get(ensembl_id, (\"\", \"\", \"\"))\n",
    "        metadata[guide_id] = {\n",
    "            \"guide_id\": guide_id,\n",
    "            \"spacer\": guides.get(guide_id, \"\"),\n",
    "            \"targeting\": \"TRUE\",\n",
    "            \"type\": \"targeting\",\n",
    "            \"guide_chr\": guide_chr,\n",
    "            \"guide_start\": guide_start,\n",
    "            \"guide_end\": guide_end,\n",
    "            \"strand\": strand,\n",
    "            \"pam\": pam,\n",
    "            \"genomic_element\": \"tss\",\n",
    "            \"intended_target_name\": ensembl_id,  # Ensembl ID from BED\n",
    "            \"intended_target_chr\": tss[0],\n",
    "            \"intended_target_start\": tss[1],\n",
    "            \"intended_target_end\": tss[2],\n",
    "            \"putative_target_genes\": gene_symbol,            \n",
    "            \"reporter\": \"\",\n",
    "            \"imperfect\": \"\"\n",
    "        }\n",
    "        \n",
    "        \n",
    "# Step 5: Write output TSV\n",
    "headers = [\n",
    "    \"guide_id\", \"spacer\", \"targeting\", \"type\", \"guide_chr\",\n",
    "    \"guide_start\", \"guide_end\", \"strand\", \"pam\", \"genomic_element\",\n",
    "    \"intended_target_name\", \"intended_target_chr\", \"intended_target_start\", \"intended_target_end\", \"putative_target_genes\", \"reporter\", \"imperfect\"\n",
    "]\n",
    "with open(output_file, \"w\", newline=\"\") as out_f:\n",
    "    writer = csv.DictWriter(out_f, fieldnames=headers, delimiter=\"\\t\")\n",
    "    writer.writeheader()\n",
    "    for guide_id in guides:\n",
    "        row = metadata.get(guide_id)\n",
    "        if row:\n",
    "            writer.writerow(row)\n",
    "        else:\n",
    "            # fallback if not aligned in SAM\n",
    "            gene_symbol = guide_id.rsplit(\".\",1)[0].upper()\n",
    "            ensembl_id = symbol_to_ensembl.get(gene_symbol, \"\")\n",
    "            tss = tss_lookup.get(ensembl_id, (\"\", \"\", \"\"))\n",
    "            row = {\n",
    "                \"guide_id\": guide_id,\n",
    "                \"spacer\": guides[guide_id],\n",
    "                \"targeting\": \"TRUE\",\n",
    "                \"type\": \"targeting\",\n",
    "                \"guide_chr\": \"\",\n",
    "                \"guide_start\": \"\",\n",
    "                \"guide_end\": \"\",\n",
    "                \"strand\": \"\",\n",
    "                \"pam\": \"\",\n",
    "                \"genomic_element\": \"tss\", \n",
    "                \"intended_target_name\": ensembl_id,\n",
    "                \"intended_target_chr\": tss[0],\n",
    "                \"intended_target_start\": tss[1],\n",
    "                \"intended_target_end\": tss[2],\n",
    "                \"putative_target_genes\": gene_symbol,\n",
    "                \"reporter\": \"\",\n",
    "                \"imperfect\": \"\"\n",
    "        }\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc14c45-08e4-4321-bbc5-566134cd3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load TSS info\n",
    "tss_lookup = {}  #  key = gene symbol, value = (chr, start, end, Ensembl ID)\n",
    "with open(tss_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) < 6:\n",
    "            continue\n",
    "        chrom, start, end, ensembl_id, gene_symbol, strand = parts\n",
    "        tss_lookup[gene_symbol.upper()] = (chrom, int(start), int(end), ensembl_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045a0f88-e994-4b1a-8ed3-9d24e3fa8abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hpc/home/rr151/SAM_Neuro_data/parse_alignment_with_gtf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hpc/home/rr151/SAM_Neuro_data/parse_alignment_with_gtf.py\n",
    "import sys\n",
    "import csv\n",
    "# Input/output files\n",
    "input_csv = \"/work/rr151/SamAIM2neuro_data/subtype_lib.csv\"\n",
    "sam_file = \"/work/rr151/SamAIM2neuro_data/SJR_subtype_lib_final.sam\"\n",
    "gtf_file = \"/work/rr151/SamAIM2neuro_data/gencode.v47.annotation.gtf\"\n",
    "output_file = \"/work/rr151/SamAIM2neuro_data/SJR_subtype_lib_final_metadata.tsv\"\n",
    "output_fasta = '/work/rr151/SamAIM2neuro_data/SJR_subtype_lib_final.fasta'\n",
    "# Step 1: Load guide sequences\n",
    "guides = {}\n",
    "with open(input_csv, 'r', newline='') as csvfile, open(output_fasta, 'w') as fastafile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader.fieldnames = [field.strip().replace('\\ufeff', '') for field in reader.fieldnames]\n",
    "    for row in reader:\n",
    "        gene = row[\"gene\"].strip()\n",
    "        spacer = row[\"protospacer\"].strip()\n",
    "        guides[gene] = spacer\n",
    "        fastafile.write(f'>{gene}\\n{spacer}\\n')\n",
    "# Step 2: Parse GTF file to build TSS lookup\n",
    "tss_lookup = {}  # key = gene_name.upper(), value = (chr, tss_start, tss_end, gene_id)\n",
    "with open(gtf_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) < 9:\n",
    "            continue\n",
    "        chrom, _, feature_type, start, end, _, strand, _, attributes = parts\n",
    "        if feature_type != \"gene\":\n",
    "            continue\n",
    "        # Extract gene_id and gene_name from attributes field\n",
    "        attr_dict = {}\n",
    "        for attr in attributes.strip().split(\";\"):\n",
    "            if attr.strip():\n",
    "                key_value = attr.strip().split(\" \", 1)\n",
    "                if len(key_value) == 2:\n",
    "                    key, value = key_value\n",
    "                    attr_dict[key] = value.replace('\"', '').strip()\n",
    "        gene_id = attr_dict.get(\"gene_id\", \"\")\n",
    "        gene_name = attr_dict.get(\"gene_name\", \"\").upper()\n",
    "        if not gene_id or not gene_name:\n",
    "            continue\n",
    "        # Determine TSS\n",
    "        start, end = int(start), int(end)\n",
    "        if strand == \"+\":\n",
    "            tss_start, tss_end = start, start + 1\n",
    "        else:\n",
    "            tss_start, tss_end = end - 1, end\n",
    "        tss_lookup[gene_name] = (chrom, tss_start, tss_end, gene_id)\n",
    "# Step 3: Parse SAM file and build metadata\n",
    "metadata = {}\n",
    "with open(sam_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"@\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        guide_id = parts[0]\n",
    "        guide_chr = parts[2]\n",
    "        guide_start = int(parts[3])\n",
    "        flag = int(parts[1])\n",
    "        strand = \"-\" if flag & 16 else \"+\"\n",
    "        seq = parts[9]\n",
    "        pam = seq[-3:] if len(seq) >= 3 else \"\"\n",
    "        guide_end = guide_start + len(seq) - 1\n",
    "        gene_symbol = guide_id.rsplit('.', 1)[0].upper()\n",
    "        tss = tss_lookup.get(gene_symbol, (\"\", \"\", \"\", \"\"))\n",
    "        metadata[guide_id] = {\n",
    "            \"guide_id\": guide_id,\n",
    "            \"spacer\": guides.get(guide_id, \"\"),\n",
    "            \"targeting\": \"TRUE\",\n",
    "            \"type\": \"targeting\",\n",
    "            \"guide_chr\": guide_chr,\n",
    "            \"guide_start\": guide_start,\n",
    "            \"guide_end\": guide_end,\n",
    "            \"strand\": strand,\n",
    "            \"pam\": pam,\n",
    "            \"genomic_element\": \"tss\",\n",
    "            \"intended_target_name\": tss[3],  # Ensembl gene ID\n",
    "            \"intended_target_chr\": tss[0],\n",
    "            \"intended_target_start\": tss[1],\n",
    "            \"intended_target_end\": tss[2],\n",
    "            \"putative_target_genes\": \"\",\n",
    "            \"reporter\": \"\",\n",
    "            \"imperfect\": \"\"\n",
    "        }\n",
    "# Step 4: Write output\n",
    "headers = [\n",
    "    \"guide_id\", \"spacer\", \"targeting\", \"type\", \"guide_chr\",\n",
    "    \"guide_start\", \"guide_end\", \"strand\", \"pam\", \"genomic_element\",\n",
    "    \"intended_target_name\", \"intended_target_chr\", \"intended_target_start\",\n",
    "    \"intended_target_end\", \"putative_target_genes\", \"reporter\", \"imperfect\"\n",
    "]\n",
    "with open(output_file, \"w\", newline=\"\") as out_f:\n",
    "    writer = csv.DictWriter(out_f, fieldnames=headers, delimiter=\"\\t\")\n",
    "    writer.writeheader()\n",
    "    for guide_id in guides:\n",
    "        gene_symbol = guide_id.rsplit('.', 1)[0].upper()\n",
    "        tss = tss_lookup.get(gene_symbol, (\"\", \"\", \"\", \"\"))\n",
    "        row = metadata.get(guide_id, {\n",
    "            \"guide_id\": guide_id,\n",
    "            \"spacer\": guides[guide_id],\n",
    "            \"targeting\": \"TRUE\",\n",
    "            \"type\": \"targeting\",\n",
    "            \"guide_chr\": \"\",\n",
    "            \"guide_start\": \"\",\n",
    "            \"guide_end\": \"\",\n",
    "            \"strand\": \"\",\n",
    "            \"pam\": \"\",\n",
    "            \"genomic_element\": \"tss\",\n",
    "            \"intended_target_name\": tss[3],\n",
    "            \"intended_target_chr\": tss[0],\n",
    "            \"intended_target_start\": tss[1],\n",
    "            \"intended_target_end\": tss[2],\n",
    "            \"putative_target_genes\": \"\",\n",
    "            \"reporter\": \"\",\n",
    "            \"imperfect\": \"\"\n",
    "        })\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1e1ca-f9a2-4e63-ba51-2c5c1180c84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
