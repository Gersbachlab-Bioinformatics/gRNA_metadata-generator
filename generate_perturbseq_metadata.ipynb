{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c4becd-34dd-4df1-a0a4-74cbdb3d902b",
   "metadata": {},
   "source": [
    "## Goal: Generate IGVF perturb-seq metadata information given input .fasta file with protospacer sequences\n",
    "\n",
    "Requirements: https://docs.google.com/document/d/1Z1SOlekIE5uGyXW41XxnszxaYdSw0wdAOUVzfy3fj3M/edit?tab=t.0#heading=h.lw69v09vjkrr\n",
    "\n",
    "Example file: /hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/example_perturbseq_seqfile.tsv\n",
    "\n",
    "Note: I was having trouble with BLAT CLI so I used webtool to get most fields. Still need PAM and TSS coordinate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25cc15-87a9-4b60-8a32-d4c091dc30e1",
   "metadata": {},
   "source": [
    "### Extract PAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b57035f-68fa-4b33-b5ab-043d6b1807ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedtools 2.30.0\u001b[m\n",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "index file /hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/perturb-seq_metadata/hg38.fa.fai not found, generating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [guide_id, PAM_sequence]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected file format.  Please use tab-delimited BED, GFF, or VCF. Perhaps you have non-integer starts or ends at line 1?\n"
     ]
    }
   ],
   "source": [
    "!module load Bedtools/2.30.0 \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def compute_upstream_with_pam(df, genome_fasta=\"/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/perturb-seq_metadata/hg38.fa\"):\n",
    "    output_bed = \"temp_upstream.bed\"\n",
    "    output_fasta = \"temp_upstream.fa\"\n",
    "\n",
    "    upstream_data = []\n",
    "\n",
    "    with open(output_bed, \"w\") as bed:\n",
    "        for _, row in df.iterrows():\n",
    "            chrom = row[\"guide_chr\"]\n",
    "            start = row[\"guide_start\"]\n",
    "            end = row[\"guide_end\"]\n",
    "            strand = row[\"strand\"]\n",
    "            guide_id = row[\"guide_id\"]\n",
    "\n",
    "            # Cas9 PAM (NGG) is on the 3' end of the guide\n",
    "            if strand == \"+\":\n",
    "                pam_start = end  # NGG is immediately downstream\n",
    "                pam_end = end + 3  # Three bases downstream\n",
    "            else:\n",
    "                pam_start = start - 3  # Three bases upstream for reverse strand\n",
    "                pam_end = start  \n",
    "\n",
    "            # Write to BED file\n",
    "            bed.write(f\"{chrom}\\t{pam_start}\\t{pam_end}\\t{guide_id}\\t.\\t{strand}\\n\")\n",
    "\n",
    "    # Run bedtools getfasta to extract sequence\n",
    "    bedtools_path = \"/opt/apps/rhel8/bedtools-2.30.0/bin/bedtools\"\n",
    "    os.system(f\"{bedtools_path} getfasta -fi {genome_fasta} -bed {output_bed} -fo {output_fasta} -s\")\n",
    "\n",
    "    # Read extracted sequences\n",
    "    with open(output_fasta, \"r\") as fasta:\n",
    "        sequences = fasta.read().splitlines()\n",
    "\n",
    "    # Process FASTA output\n",
    "    for i in range(0, len(sequences), 2):  # FASTA format is >header, seq\n",
    "        guide_id = sequences[i].strip(\">\").split(\":\")[0]  # Extract guide_id from header\n",
    "        pam_seq = sequences[i + 1]  # Extract PAM sequence\n",
    "\n",
    "        upstream_data.append([guide_id, pam_seq])\n",
    "\n",
    "    # Create DataFrame\n",
    "    upstream_df = pd.DataFrame(upstream_data, columns=[\"guide_id\", \"PAM_sequence\"])\n",
    "    \n",
    "    # Save output\n",
    "    upstream_df.to_csv(\"upstream_regions_with_pam.csv\", sep=\",\", index=False)\n",
    "    return upstream_df\n",
    "\n",
    "# Read input CSV\n",
    "df = pd.read_csv(\"/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/perturb-seq_metadata/PAM_input.csv\", sep=\",\")  # Adjust separator if needed\n",
    "\n",
    "# Compute upstream regions and extract PAM\n",
    "upstream_df = compute_upstream_with_pam(df)\n",
    "\n",
    "print(upstream_df.head())  # Show output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fc1b9b9-a1ca-4d55-94df-6524ef743588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "831e5bba-0088-4694-9fee-025c3bb5ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected fieldnames: ['\\ufeffgene', 'protospacer', 'oligo']\n",
      "{'\\ufeffgene': 'ADNP.1', 'protospacer': 'AACCCCCCCTGGGGAAAAGG', 'oligo': 'ATATATCTTGTGGAAAGGACGAAACACCGAACCCCCCCTGGGGAAAAGGGTTTAAGAGCTATGCTGGAAACAGCATAG'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('/hpc/group/gersbachlab/sjr72/IGVF_AtN_Submission_Files/grna_libs/SJR_CRISPRa_TF_lib_final.csv', 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    print(\"Detected fieldnames:\", reader.fieldnames)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        break  # Just check the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53b5455-861c-4b20-ac89-e214dd253045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "input_csv = '/work/rr151/SamAIM2neuro_data/subtype_lib.csv'\n",
    "output_fasta = '/work/rr151/SamAIM2neuro_data/SJR_subtype_lib_final.fasta'\n",
    "with open(input_csv, 'r', newline='') as csvfile, open(output_fasta, 'w') as fastafile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader.fieldnames = [field.strip().replace('\\ufeff', '') for field in reader.fieldnames]\n",
    "    for row in reader:\n",
    "        gene = row['gene'].strip()\n",
    "        spacer = row['protospacer'].strip()\n",
    "        fastafile.write(f'>{gene}\\n{spacer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee85cd1c-1ad1-4e27-903e-47eba0d24859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bowtie2 2.4.4-rhel8\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "module load Bowtie2/2.4.4-rhel8\n",
    "#module load Bowtie/1.2.2\n",
    "#bowtie2-build '/hpc/group/gersbachlab/Reference_Data/Genomes/hg38/hg38.fa' '/work/rr151/SamAIM2neuro_data/hg38_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049db69e-1d98-40b5-b5f7-321a05e8c556",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-c898449e6a35>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-c898449e6a35>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    echo \"Parsing SAM to metadata...\"\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "# Inputs\n",
    "FASTA=\"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final.fasta\"\n",
    "BOWTIE_INDEX=\"/work/rr151/SamAIM2neuro_data/hg38_index\"\n",
    "SAM_OUT=\"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final.sam\"\n",
    "TSV_OUT=\"/work/rr151/SamAIM2neuro_data/SJR_CRISPRa_TF_lib_final_metadata.tsv\"\n",
    "\n",
    "#module load Bowtie2/2.4.4-rhel8\n",
    "# Align using Bowtie\n",
    "#echo \"Running Bowtie...\"\n",
    "#bowtie -f -v 0 -a --best --strata $BOWTIE_INDEX $FASTA > $SAM_OUT\n",
    "#bowtie2 -f -x $BOWTIE_INDEX -U $FASTA -S $SAM_OUT\n",
    "#bowtie2 -f -x /work/rr151/SamAIM2neuro_data/hg38_index -U SJR_subtype_lib_final.fasta -S SJR_subtype_lib_final.sam\n",
    "# Generate metadata\n",
    "#python3 /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_metadata.py $FASTA $SAM_OUT $TSV_OUT\n",
    "python3 /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_metadata.py $SAM_OUT $TSV_OUT\n",
    "echo \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045a0f88-e994-4b1a-8ed3-9d24e3fa8abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hpc/home/rr151/SAM_Neuro_data/parse_alignment_with_gtf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hpc/home/rr151/SAM_Neuro_data/parse_alignment_with_gtf.py\n",
    "import sys\n",
    "import csv\n",
    "sam_file = sys.argv[2]\n",
    "output_file = sys.argv[1]\n",
    "\n",
    "# Input/output files\n",
    "input_csv = \"/work/rr151/SamAIM2neuro_data/subtype_lib.csv\"\n",
    "sam_file = \"/work/rr151/SamAIM2neuro_data/SJR_subtype_lib_final.sam\"\n",
    "gtf_file = \"/work/rr151/SamAIM2neuro_data/gencode.v47.annotation.gtf\"\n",
    "output_file = \"/work/rr151/SamAIM2neuro_data/SJR_subtype_lib_final_metadata.tsv\"\n",
    "output_fasta = '/work/rr151/SamAIM2neuro_data/SJR_subtype_lib_final.fasta'\n",
    "# Load guide sequences\n",
    "guides = {}\n",
    "with open(input_csv, 'r', newline='') as csvfile, open(output_fasta, 'w') as fastafile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader.fieldnames = [field.strip().replace('\\ufeff', '') for field in reader.fieldnames]\n",
    "    for row in reader:\n",
    "        gene = row[\"gene\"].strip()\n",
    "        spacer = row[\"protospacer\"].strip()\n",
    "        guides[gene] = spacer\n",
    "        fastafile.write(f'>{gene}\\n{spacer}\\n')\n",
    "# Parse GTF file to build TSS lookup\n",
    "tss_lookup = {}  # key = gene_name.upper(), value = (chr, tss_start, tss_end, gene_id)\n",
    "with open(gtf_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) < 9:\n",
    "            continue\n",
    "        chrom, _, feature_type, start, end, _, strand, _, attributes = parts\n",
    "        if feature_type != \"gene\":\n",
    "            continue\n",
    "        # Extract gene_id and gene_name from attributes field\n",
    "        attr_dict = {}\n",
    "        for attr in attributes.strip().split(\";\"):\n",
    "            if attr.strip():\n",
    "                key_value = attr.strip().split(\" \", 1)\n",
    "                if len(key_value) == 2:\n",
    "                    key, value = key_value\n",
    "                    attr_dict[key] = value.replace('\"', '').strip()\n",
    "        gene_id = attr_dict.get(\"gene_id\", \"\")\n",
    "        gene_name = attr_dict.get(\"gene_name\", \"\").upper()\n",
    "        if not gene_id or not gene_name:\n",
    "            continue\n",
    "        # Determine TSS\n",
    "        start, end = int(start), int(end)\n",
    "        if strand == \"+\":\n",
    "            tss_start, tss_end = start, start + 1\n",
    "        else:\n",
    "            tss_start, tss_end = end - 1, end\n",
    "        tss_lookup[gene_name] = (chrom, tss_start, tss_end, gene_id)\n",
    "# Parse SAM file and build metadata\n",
    "metadata = {}\n",
    "with open(sam_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"@\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        guide_id = parts[0]\n",
    "        guide_chr = parts[2]\n",
    "        guide_start = int(parts[3])\n",
    "        flag = int(parts[1])\n",
    "        strand = \"-\" if flag & 16 else \"+\"\n",
    "        seq = parts[9]\n",
    "        pam = seq[-3:] if len(seq) >= 3 else \"\"\n",
    "        guide_end = guide_start + len(seq) - 1\n",
    "        gene_symbol = guide_id.rsplit('.', 1)[0].upper()\n",
    "        tss = tss_lookup.get(gene_symbol, (\"\", \"\", \"\", \"\"))\n",
    "        metadata[guide_id] = {\n",
    "            \"guide_id\": guide_id,\n",
    "            \"spacer\": guides.get(guide_id, \"\"),\n",
    "            \"targeting\": \"TRUE\",\n",
    "            \"type\": \"targeting\",\n",
    "            \"guide_chr\": guide_chr,\n",
    "            \"guide_start\": guide_start,\n",
    "            \"guide_end\": guide_end,\n",
    "            \"strand\": strand,\n",
    "            \"pam\": pam,\n",
    "            \"genomic_element\": \"tss\",\n",
    "            \"intended_target_name\": tss[3],  # Ensembl gene ID\n",
    "            \"intended_target_chr\": tss[0],\n",
    "            \"intended_target_start\": tss[1],\n",
    "            \"intended_target_end\": tss[2],\n",
    "            \"putative_target_genes\": \"\",\n",
    "            \"reporter\": \"\",\n",
    "            \"imperfect\": \"\"\n",
    "        }\n",
    "# Write output\n",
    "headers = [\n",
    "    \"guide_id\", \"spacer\", \"targeting\", \"type\", \"guide_chr\",\n",
    "    \"guide_start\", \"guide_end\", \"strand\", \"pam\", \"genomic_element\",\n",
    "    \"intended_target_name\", \"intended_target_chr\", \"intended_target_start\",\n",
    "    \"intended_target_end\", \"putative_target_genes\", \"reporter\", \"imperfect\"\n",
    "]\n",
    "with open(output_file, \"w\", newline=\"\") as out_f:\n",
    "    writer = csv.DictWriter(out_f, fieldnames=headers, delimiter=\"\\t\")\n",
    "    writer.writeheader()\n",
    "    for guide_id in guides:\n",
    "        gene_symbol = guide_id.rsplit('.', 1)[0].upper()\n",
    "        tss = tss_lookup.get(gene_symbol, (\"\", \"\", \"\", \"\"))\n",
    "        row = metadata.get(guide_id, {\n",
    "            \"guide_id\": guide_id,\n",
    "            \"spacer\": guides[guide_id],\n",
    "            \"targeting\": \"TRUE\",\n",
    "            \"type\": \"targeting\",\n",
    "            \"guide_chr\": \"\",\n",
    "            \"guide_start\": \"\",\n",
    "            \"guide_end\": \"\",\n",
    "            \"strand\": \"\",\n",
    "            \"pam\": \"\",\n",
    "            \"genomic_element\": \"tss\",\n",
    "            \"intended_target_name\": tss[3],\n",
    "            \"intended_target_chr\": tss[0],\n",
    "            \"intended_target_start\": tss[1],\n",
    "            \"intended_target_end\": tss[2],\n",
    "            \"putative_target_genes\": \"\",\n",
    "            \"reporter\": \"\",\n",
    "            \"imperfect\": \"\"\n",
    "        })\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201b7605-61cd-4f8b-a826-2bf5cbcce75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Input/output files (Update with your paths)\n",
    "input_csv = \"/work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib.csv\"\n",
    "output_fasta = '/work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib_mm10.fasta'\n",
    "with open(input_csv, 'r', newline='') as csvfile, open(output_fasta, 'w') as fastafile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader.fieldnames = [field.strip().replace('\\ufeff', '') for field in reader.fieldnames]\n",
    "    for row in reader:\n",
    "        gene = row[\"gene\"].strip()\n",
    "        spacer = row[\"protospacer\"].strip()\n",
    "        #guides[gene] = spacer\n",
    "        fastafile.write(f'>{gene}\\n{spacer}\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c71d8098-c8d5-4946-ac75-8ab8343dbe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bowtie2 2.4.4-rhel8\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "module load Bowtie2/2.4.4-rhel8\n",
    "#bowtie2 -f -x /hpc/group/gersbachlab/Reference_Data/Genomes/mm10/bowtie2/GRCm38 -U /work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib_mm10.fasta -S /work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4531243-1334-41a0-b05b-fb3f5026e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Metadata written to /work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib_metadata_mm10.tsv\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash \n",
    "\n",
    "TSV_OUT=\"/work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib_metadata_mm10.tsv\"\n",
    "# Align using Bowtie\n",
    "#echo \"Running Bowtie...\"\n",
    "#bowtie -f -v 0 -a --best --strata $BOWTIE_INDEX $FASTA > $SAM_OUT\n",
    "#bowtie2 -f -x $BOWTIE_INDEX -U $FASTA -S $SAM_OUT\n",
    "#bowtie2 -f -x /work/rr151/SamAIM2neuro_data/hg38_index -U SJR_subtype_lib_final.fasta -S SJR_subtype_lib_final.sam\n",
    "# Generate metadata\n",
    "#python3 /hpc/home/rr151/SAM_Neuro_data/parse_alignment_to_metadata.py $FASTA $SAM_OUT $TSV_OUT\n",
    "!python3 /hpc/home/rr151/SAM_Neuro_data/parse_alignment_with_mm10_gtf.py $TSV_OUT\n",
    "!echo \"Done. Metadata written to $TSV_OUT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05f1e1ca-f9a2-4e63-ba51-2c5c1180c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hpc/home/rr151/SAM_Neuro_data/parse_alignment_with_mm10_gtf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hpc/home/rr151/SAM_Neuro_data/parse_alignment_with_mm10_gtf.py\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "output_file = sys.argv[1]\n",
    "\n",
    "# Input/output files (Update with your paths)\n",
    "input_csv = \"/work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib.csv\"\n",
    "sam_file = \"/work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib.sam\"\n",
    "gtf_file = \"/hpc/group/gersbachlab/Reference_Data/Gencode/vM25/gencode.vM25.annotation.gtf\"  # mm10 GTF\n",
    "output_file = \"/work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib_metadata_mm10.tsv\"\n",
    "output_fasta = '/work/rr151/SamAIM2neuro_data/mPA_CRISPRa_lib_mm10.fasta'\n",
    "# Load guide sequences\n",
    "guides = {}\n",
    "with open(input_csv, 'r', newline='') as csvfile, open(output_fasta, 'w') as fastafile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader.fieldnames = [field.strip().replace('\\ufeff', '') for field in reader.fieldnames]\n",
    "    for row in reader:\n",
    "        gene = row[\"gene\"].strip()\n",
    "        spacer = row[\"protospacer\"].strip()\n",
    "        guides[gene] = spacer\n",
    "        fastafile.write(f'>{gene}\\n{spacer}\\n')\n",
    "# Parse GTF file to build TSS lookup\n",
    "tss_lookup = {}  # key = gene_name.upper(), value = (chr, tss_start, tss_end, gene_id)\n",
    "with open(gtf_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) < 9:\n",
    "            continue\n",
    "        chrom, _, feature_type, start, end, _, strand, _, attributes = parts\n",
    "        if feature_type != \"gene\":\n",
    "            continue\n",
    "        # Parse GTF attributes\n",
    "        attr_dict = {}\n",
    "        for attr in attributes.strip().split(\";\"):\n",
    "            if attr.strip():\n",
    "                key_value = attr.strip().split(\" \", 1)\n",
    "                if len(key_value) == 2:\n",
    "                    key, value = key_value\n",
    "                    attr_dict[key] = value.replace('\"', '').strip()\n",
    "        gene_id = attr_dict.get(\"gene_id\", \"\")\n",
    "        gene_name = attr_dict.get(\"gene_name\", \"\").upper()\n",
    "        if not gene_id or not gene_name:\n",
    "            continue\n",
    "        # Calculate TSS\n",
    "        start, end = int(start), int(end)\n",
    "        if strand == \"+\":\n",
    "            tss_start, tss_end = start, start + 1\n",
    "        else:\n",
    "            tss_start, tss_end = end - 1, end\n",
    "        tss_lookup[gene_name] = (chrom, tss_start, tss_end, gene_id)\n",
    "# Parse SAM file and build metadata\n",
    "metadata = {}\n",
    "with open(sam_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"@\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        guide_id = parts[0]\n",
    "        guide_chr = parts[2]\n",
    "        guide_start = int(parts[3])\n",
    "        flag = int(parts[1])\n",
    "        strand = \"-\" if flag & 16 else \"+\"\n",
    "        seq = parts[9]\n",
    "        pam = seq[-3:] if len(seq) >= 3 else \"\"\n",
    "        guide_end = guide_start + len(seq) - 1\n",
    "        gene_symbol = guide_id.rsplit('.', 1)[0].upper()\n",
    "        tss = tss_lookup.get(gene_symbol, (\"\", \"\", \"\", \"\"))\n",
    "        metadata[guide_id] = {\n",
    "            \"guide_id\": guide_id,\n",
    "            \"spacer\": guides.get(guide_id, \"\"),\n",
    "            \"targeting\": \"TRUE\",\n",
    "            \"type\": \"targeting\",\n",
    "            \"guide_chr\": guide_chr,\n",
    "            \"guide_start\": guide_start,\n",
    "            \"guide_end\": guide_end,\n",
    "            \"strand\": strand,\n",
    "            \"pam\": pam,\n",
    "            \"genomic_element\": \"tss\",\n",
    "            \"intended_target_name\": tss[3],  # Ensembl gene ID\n",
    "            \"intended_target_chr\": tss[0],\n",
    "            \"intended_target_start\": tss[1],\n",
    "            \"intended_target_end\": tss[2],\n",
    "            \"putative_target_genes\": \"\",\n",
    "            \"reporter\": \"\",\n",
    "            \"imperfect\": \"\"\n",
    "        }\n",
    "# Write output\n",
    "headers = [\n",
    "    \"guide_id\", \"spacer\", \"targeting\", \"type\", \"guide_chr\",\n",
    "    \"guide_start\", \"guide_end\", \"strand\", \"pam\", \"genomic_element\",\n",
    "    \"intended_target_name\", \"intended_target_chr\", \"intended_target_start\",\n",
    "    \"intended_target_end\", \"putative_target_genes\", \"reporter\", \"imperfect\"\n",
    "]\n",
    "with open(output_file, \"w\", newline=\"\") as out_f:\n",
    "    writer = csv.DictWriter(out_f, fieldnames=headers, delimiter=\"\\t\")\n",
    "    writer.writeheader()\n",
    "    for guide_id in guides:\n",
    "        gene_symbol = guide_id.rsplit('.', 1)[0].upper()\n",
    "        tss = tss_lookup.get(gene_symbol, (\"\", \"\", \"\", \"\"))\n",
    "        row = metadata.get(guide_id, {\n",
    "            \"guide_id\": guide_id,\n",
    "            \"spacer\": guides[guide_id],\n",
    "            \"targeting\": \"TRUE\",\n",
    "            \"type\": \"targeting\",\n",
    "            \"guide_chr\": \"\",\n",
    "            \"guide_start\": \"\",\n",
    "            \"guide_end\": \"\",\n",
    "            \"strand\": \"\",\n",
    "            \"pam\": \"\",\n",
    "            \"genomic_element\": \"tss\",\n",
    "            \"intended_target_name\": tss[3],\n",
    "            \"intended_target_chr\": tss[0],\n",
    "            \"intended_target_start\": tss[1],\n",
    "            \"intended_target_end\": tss[2],\n",
    "            \"putative_target_genes\": \"\",\n",
    "            \"reporter\": \"\",\n",
    "            \"imperfect\": \"\"\n",
    "        })\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c62659-13bd-4ebc-97a7-5d90156e8304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
